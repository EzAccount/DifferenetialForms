 \documentclass{article}
 \usepackage{amsmath,amsthm,amssymb}
 \usepackage{mathtext}
 \usepackage[T1,T2A]{fontenc}
 \usepackage[utf8]{inputenc}
 \usepackage[english,russian]{babel}
 \usepackage{fancyhdr}
 \usepackage[a4paper]{geometry}
 \pagestyle{fancy}
 \fancyhf{}
 \newtheorem{defn}{Def}
 \newtheorem{example}{Ex}
 \newtheorem{theorem}{Th}
 \DeclareMathOperator{\im}{im}
 
 \begin{document}
 	
 	\subsection*{Литература}
 	Базовая:
 	\begin{itemize}
 		\item Зорич В. А., Математический анализ, Том II.
 		\item Арнольд В. И., Математические методы классической механики. 
 		\item  W. Rudin, Principles of mathematical analysis
 	\end{itemize}
 	Продвинутая:
 	\begin{itemize}
 		\item С. П. Новиков, И. А. Тайманов, Современные геометрические структуры и поля.
 		\item Картан А., Дифференциальное исчисление. Дифференциальные формы.
 		\item H. Flanders, Differential forms and applications to the physical sciences
 		\item M. Spivak, Calculus on manifolds
 		\item Bishop, R.; Goldberg, S. I. (1980), Tensor analysis on manifolds
 	\end{itemize}
 	\newpage
 	Set G with binary operation $*: G \times G \to G$ is called a \textit{group} $(G, *)$ if:
 	\begin{enumerate}
 		\item $\forall a,b,c \in G: a*(b*c) = (a*b)*c $
 		\item $\exists e \in G: \forall a \in G, a*e=e*a=a$
 		\item $\forall a \in G, \exists b\in G: a*b = e$
 	\end{enumerate}
 	{\centering
 		\section*{Problem 	Set - 1}}
 	\begin{enumerate}
 		\item Prove that the set of matrices of form  $\left(\begin{matrix}a & b\\ -b & a\end{matrix}\right) a,b \in \mathbb{R}$ with standard multiplication ($c_{ij} = a_{ik} b_{kj}$) is a group.
 		\item Show that vectors of vector space with addition is a group.
 		\item Prove that determinant of skew-symmetric matrix of odd size is zero.
 		
 		\item Let C = $\left(\begin{matrix}A & X\\ 0 & B\end{matrix}\right) A,X, B \in \mathbb{R}^{n \times n}$. Prove that $\det С = \det A \det B$
 		
 		\item Prove that $\det \text{adj} A = (\det A)^{n-1}$ [adj - adjoint matrix]
 		
 		\item Evaluate  $\det A$, if
 		
 		a) $a_{ij} = \min(i,j)$
 		
 		b) $a_{ij} = \max(i,j)$ 
 		
 		\item Find $ \begin{vmatrix}
 		1 & -1 &    &    & 0   \\
 		-1  & 1       & -1   &      &    \\
 		&       \ddots &           \ddots&     \ddots      &    \\
 		&         &           -1&          1 & -1\\
 		0  &         &           &          -1 & 1
 		\end{vmatrix}
 		$
 		
 		\item Find $\frac{\partial} {\partial a_{ij}} \det A$
 	\end{enumerate}
	
 \newpage
 
 
 \section{Some facts on Cartesian coordinates} Let $\{e_i\}$ be the basis. Here and later we use $(\cdot, \cdot), [\cdot, \cdot]$ for scalar and vector product; repeated index is a short notation for summation.
 $$(e_i, e_j)=\delta_{ij}$$
 $$[e_i, e_j] = \epsilon_{ijk}e_k$$
 $$\epsilon_{ijk}\epsilon_{klm} = \delta_{il}\delta_{jm} - \delta_{im}\delta_{jl}$$
 $$V=e_i V^i_{(e_i)}$$
 Index notation might be sometimes useful, for example:
 \begin{align*}
 [\mathbf{A}, [\mathbf{B},\mathbf{C}]] &= [e_i, [e_l, e_m]] A^i B^l C^m\\
 &= [e_i, e_k] \epsilon_{klm} A^i B^l C^m \\
 &= e_j \epsilon_{jik}\epsilon_{klm} A^i B^l C^m \\
 &= e_j (\delta_{jl}\delta_{im} - \delta_{jm}\delta_{il}) A^i B^l C^m \\
 &= \mathbf{B} (\mathbf{A}\cdot \mathbf{C}) - \mathbf{C} (\mathbf{A}\cdot \mathbf{B})\\
 \end{align*}
 \section{Curvilinear coordinates}
Let  $x = x(\zeta_1, \zeta_2, \zeta_3)$,$y = y(\zeta_1, \zeta_2, \zeta_3)$,$z = z(\zeta_1, \zeta_2, \zeta_3)$ be three given maps.
In each point of the space the following vectors are well defined:
 $$\mathbf{i}_i = \mathbf{e_a} \frac{\partial x^a}{\partial \zeta^i}.$$
 Furthermore, for each point $p$ of some space $M$ (which we siliently agreed to consider a differential manifold) a vector space is defined,  $\mathbf{T_p M}$, called tangent space. Vectors $\mathbf{i}_i (\zeta)$ form basis of this vector space in point  $p$ (the point is defined with its local coordinates $\zeta$). Vectors $\mathbf{i}_i$ might differ for different points, may not be unit or orthogonal. Let us introduce $g_{ij}$ which is just a scalar product of all basis vectors by pairs.
 $$g_{ij} = (\mathbf{i}_i, \mathbf{i}_j)$$
 \begin{defn}
 	Tensor  $g_{ij}$ is called metric tensor
 \end{defn}
 
 Let's represent arbitrary vectors, in the same way as we did in Cartesian coordinates,  $\mathbf{V,W}$ as sum of basis vectors $\mathbf{i}$ with coefficients.  For scalar product we obtain the following:
 $$(\mathbf{V,W)} = (\mathbf{i}_i, \mathbf{i}_k) V^i W^k = g_{ik} V^i W^k = V_i W^i,$$
 where the last equality defines \textit{covariant} components $V_i = g_{ij} V^j$ of vector $\mathbf{V}$ ($V^k$ is called \textit{contravariant} components). One may check that this definition agrees with the one that was provided in linear algebra course. Following the linear algebra logic covariant components $V_k$ can be viewed as a linear form (linear functional). The action of that form to the arbitrary vector (at the same point) is simply:
 $${V}(\cdot) = (\mathbf{V}, \cdot)$$
 
 All linear forms $\zeta^i$ forms a vector space (called dual to the vector space)   
 

 
 \end{document}
 
